{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sokrypton/ColabFold/blob/main/AlphaFold2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4yBrceuFbf3"
   },
   "source": [
    "#ColabFold: AlphaFold2 w/ MMseqs2\n",
    "-----------------\n",
    "- <b><font color='green'>21Aug2021: The MSA/Templates issues should now be resolved! Please report any errors you see.</font></b>\n",
    "-----------------\n",
    "<img src=\"https://raw.githubusercontent.com/sokrypton/ColabFold/main/.github/ColabFold_Marv_Logo_Small.png\" height=\"256\" align=\"right\" style=\"height:256px\">\n",
    "\n",
    "Easy to use AlphaFold2 [(Jumper et al. 2021)](https://www.nature.com/articles/s41586-021-03819-2) protein structure prediction using multiple sequence alignments generated through an MMseqs2 API. For details, refer to our manuscript:\n",
    "\n",
    "[Mirdita M, Ovchinnikov S, Steinegger M. ColabFold - Making protein folding accessible to all.\n",
    "*bioRxiv*, 2021](https://www.biorxiv.org/content/10.1101/2021.08.15.456425v1) \n",
    "\n",
    "- This notebook provides basic functionality, for more advanced options (such as modeling heterocomplexes, increasing recycles, sampling, etc.) see our [advanced notebook](https://colab.research.google.com/github/sokrypton/ColabFold/blob/main/beta/AlphaFold2_advanced.ipynb).\n",
    "- This notebook replaces the homology detection of AlphaFold2 with MMseqs2. For a comparision against the [Deepmind Colab](https://colab.research.google.com/github/deepmind/alphafold/blob/main/notebooks/AlphaFold.ipynb) and the full [AlphaFold2](https://github.com/deepmind/alphafold) system read our [preprint](https://www.biorxiv.org/content/10.1101/2021.08.15.456425v1). \n",
    "\n",
    "\n",
    "<strong>For more details, see <a href=\"#Instructions\">bottom</a> of the notebook and checkout the [ColabFold GitHub](https://github.com/sokrypton/ColabFold). </strong>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "kOblAo-xetgx"
   },
   "outputs": [],
   "source": [
    "#@title Input protein sequence, then hit `Runtime` -> `Run all`\n",
    "from google.colab import files\n",
    "import os.path\n",
    "import re\n",
    "import hashlib\n",
    "\n",
    "def add_hash(x,y):\n",
    "  return x+\"_\"+hashlib.sha1(y.encode()).hexdigest()[:5]\n",
    "\n",
    "query_sequence = 'PIAQIHILEGRSDEQKETLIREVSEAISRSLDAPLTSVRVIITEMAKGHFGIGGELASK' #@param {type:\"string\"}\n",
    "# remove whitespaces\n",
    "query_sequence = \"\".join(query_sequence.split())\n",
    "query_sequence = re.sub(r'[^a-zA-Z]','', query_sequence).upper()\n",
    "\n",
    "jobname = 'test' #@param {type:\"string\"}\n",
    "# remove whitespaces\n",
    "jobname = \"\".join(jobname.split())\n",
    "jobname = re.sub(r'\\W+', '', jobname)\n",
    "jobname = add_hash(jobname, query_sequence)\n",
    "\n",
    "\n",
    "with open(f\"{jobname}.fasta\", \"w\") as text_file:\n",
    "    text_file.write(f\">1\\n{query_sequence}\")\n",
    "\n",
    "# number of models to use\n",
    "#@markdown ---\n",
    "#@markdown ### Advanced settings\n",
    "msa_mode = \"MMseqs2 (UniRef+Environmental)\" #@param [\"MMseqs2 (UniRef+Environmental)\", \"MMseqs2 (UniRef only)\",\"single_sequence\",\"custom\"]\n",
    "num_models = 5 #@param [1,2,3,4,5] {type:\"raw\"}\n",
    "use_msa = True if msa_mode.startswith(\"MMseqs2\") else False\n",
    "use_env = True if msa_mode == \"MMseqs2 (UniRef+Environmental)\" else False\n",
    "use_custom_msa = True if msa_mode == \"custom\" else False\n",
    "use_amber = False #@param {type:\"boolean\"}\n",
    "use_templates = False #@param {type:\"boolean\"}\n",
    "#@markdown ---\n",
    "#@markdown ### Experimental options\n",
    "homooligomer = 1 #@param [1,2,3,4,5,6,7,8] {type:\"raw\"}\n",
    "save_to_google_drive = False #@param {type:\"boolean\"}\n",
    "#@markdown ---\n",
    "#@markdown Don't forget to hit `Runtime` -> `Run all` after updating the form.\n",
    "\n",
    "\n",
    "if homooligomer > 1:\n",
    "  if use_amber:\n",
    "    print(\"amber disabled: amber is not currently supported for homooligomers\")\n",
    "    use_amber = False\n",
    "  if use_templates:\n",
    "    print(\"templates disabled: templates are not currently supported for homooligomers\")\n",
    "    use_templates = False\n",
    "\n",
    "with open(f\"{jobname}.log\", \"w\") as text_file:\n",
    "    text_file.write(\"num_models=%s\\n\" % num_models)\n",
    "    text_file.write(\"use_amber=%s\\n\" % use_amber)\n",
    "    text_file.write(\"use_msa=%s\\n\" % use_msa)\n",
    "    text_file.write(\"msa_mode=%s\\n\" % msa_mode)\n",
    "    text_file.write(\"use_templates=%s\\n\" % use_templates)\n",
    "    text_file.write(\"homooligomer=%s\\n\" % homooligomer)\n",
    "\n",
    "# decide which a3m to use\n",
    "if use_msa:\n",
    "  a3m_file = f\"{jobname}.a3m\"\n",
    "elif use_custom_msa:\n",
    "  a3m_file = f\"{jobname}.custom.a3m\"\n",
    "  if not os.path.isfile(a3m_file):\n",
    "    custom_msa_dict = files.upload()\n",
    "    custom_msa = list(custom_msa_dict.keys())[0]\n",
    "    header = 0\n",
    "    import fileinput\n",
    "    for line in fileinput.FileInput(custom_msa,inplace=1):\n",
    "      if line.startswith(\">\"):\n",
    "         header = header + 1\n",
    "      if line.startswith(\"#\"):\n",
    "        continue\n",
    "      if line.rstrip() == False:\n",
    "        continue\n",
    "      if line.startswith(\">\") == False and header == 1:\n",
    "         query_sequence = line.rstrip()\n",
    "      print(line, end='')\n",
    "\n",
    "    os.rename(custom_msa, a3m_file)\n",
    "    print(f\"moving {custom_msa} to {a3m_file}\")\n",
    "else:\n",
    "  a3m_file = f\"{jobname}.single_sequence.a3m\"\n",
    "  with open(a3m_file, \"w\") as text_file:\n",
    "    text_file.write(\">1\\n%s\" % query_sequence)\n",
    "\n",
    "if save_to_google_drive:\n",
    "  from pydrive.drive import GoogleDrive\n",
    "  from pydrive.auth import GoogleAuth\n",
    "  from google.colab import auth\n",
    "  from oauth2client.client import GoogleCredentials\n",
    "  auth.authenticate_user()\n",
    "  gauth = GoogleAuth()\n",
    "  gauth.credentials = GoogleCredentials.get_application_default()\n",
    "  drive = GoogleDrive(gauth)\n",
    "  print(\"You are logged into Google Drive and are good to go!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "iccGdbe_Pmt9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#@title Install dependencies\n",
    "%%bash -s $use_amber $use_msa $use_templates\n",
    "\n",
    "set -e\n",
    "\n",
    "USE_AMBER=$1\n",
    "USE_MSA=$2\n",
    "USE_TEMPLATES=$3\n",
    "\n",
    "# install dependencies\n",
    "pip -q install biopython dm-haiku ml-collections py3Dmol\n",
    "# Trick for dev stage because otherwise pip won't install newer git versions\n",
    "pip uninstall -y -q local2fold\n",
    "pip install -q git+https://github.com/konstin/ColabFold # Also installs the patched alphafold (which should be used directly eventually)\n",
    "\n",
    "# download model params (~1 min)\n",
    "python -m local2fold.download\n",
    "\n",
    "# download libraries for interfacing with MMseqs2 API\n",
    "if [ ${USE_MSA} == \"True\" ] || [ ${USE_TEMPLATES} == \"True\" ]; then\n",
    "  if [ ! -f MMSEQ2_READY ]; then\n",
    "    apt-get -qq -y update 2>&1 1>/dev/null\n",
    "    apt-get -qq -y install jq curl zlib1g gawk 2>&1 1>/dev/null\n",
    "    touch MMSEQ2_READY\n",
    "  fi\n",
    "fi\n",
    "# setup conda\n",
    "if [ ${USE_AMBER} == \"True\" ] || [ ${USE_TEMPLATES} == \"True\" ]; then\n",
    "  if [ ! -f CONDA_READY ]; then\n",
    "    wget -qnc https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "    bash Miniconda3-latest-Linux-x86_64.sh -bfp /usr/local 2>&1 1>/dev/null\n",
    "    rm Miniconda3-latest-Linux-x86_64.sh\n",
    "    touch CONDA_READY\n",
    "  fi\n",
    "fi\n",
    "# setup template search\n",
    "if [ ${USE_TEMPLATES} == \"True\" ] && [ ! -f HH_READY ]; then\n",
    "  conda install -y -q -c conda-forge -c bioconda kalign3=3.2.2 hhsuite=3.3.0 python=3.7 2>&1 1>/dev/null\n",
    "  touch HH_READY\n",
    "fi\n",
    "# setup openmm for amber refinement\n",
    "if [ ${USE_AMBER} == \"True\" ] && [ ! -f AMBER_READY ]; then\n",
    "  conda install -y -q -c conda-forge openmm=7.5.1 python=3.7 pdbfixer 2>&1 1>/dev/null\n",
    "  wget -qnc https://raw.githubusercontent.com/deepmind/alphafold/main/docker/openmm.patch\n",
    "  (cd /usr/local/lib/python3.7/site-packages; patch -s -p0 < /content/openmm.patch)\n",
    "  wget -qnc https://git.scicore.unibas.ch/schwede/openstructure/-/raw/7102c63615b64735c4941278d92b554ec94415f8/modules/mol/alg/src/stereo_chemical_props.txt\n",
    "  mv stereo_chemical_props.txt $(python -c \"import alphafold.common; from pathlib import Path; print(Path(alphafold.common.__file__).parent)\")\n",
    "  touch AMBER_READY\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "jFNCnjI9_DUG"
   },
   "outputs": [],
   "source": [
    "#@title Import libraries\n",
    "\n",
    "# hiding warning messages\n",
    "import warnings\n",
    "from absl import logging\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "import sys\n",
    "from alphafold.data import pipeline\n",
    "from pathlib import Path\n",
    "\n",
    "from local2fold.single_sequence import plot_confidence, plot_plddt_legend, get_msa, predict_structure, handle_homooligomer\n",
    "from local2fold.plot import plot_lddt, plot_predicted_alignment_error\n",
    "from local2fold.pdb import show_pdb\n",
    "from local2fold.models import load_models_and_params\n",
    "from local2fold.citations import write_bibtex\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.set_verbosity(\"error\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "if use_amber and \"relax\" not in dir():\n",
    "  sys.path.insert(0, '/usr/local/lib/python3.7/site-packages/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "_sztQyz29DIC"
   },
   "outputs": [],
   "source": [
    "#@title Call MMseqs2 to get MSA/templates\n",
    "\n",
    "write_bibtex(use_msa, use_env, use_templates, use_amber, Path(\".\"), f\"{jobname}.bibtex\")\n",
    "msa, deletion_matrix, template_features = get_msa(\n",
    "    query_sequence,\n",
    "    jobname,\n",
    "    homooligomer,\n",
    "    use_templates,\n",
    "    use_msa,\n",
    "    use_env,\n",
    "    a3m_file,\n",
    ")\n",
    "deletion_matrices, msas = handle_homooligomer(deletion_matrix, homooligomer, msa, query_sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "hUYApPElB30u"
   },
   "outputs": [],
   "source": [
    "#@title Gather input features, predict structure\n",
    "\n",
    "# collect model weights\n",
    "model_runner_and_params = load_models_and_params(num_models)\n",
    "\n",
    "# gather features\n",
    "feature_dict = {\n",
    "    **pipeline.make_sequence_features(sequence=query_sequence*homooligomer,\n",
    "                                      description=\"none\",\n",
    "                                      num_res=len(query_sequence)*homooligomer),\n",
    "    **pipeline.make_msa_features(msas=msas,deletion_matrices=deletion_matrices),\n",
    "    **template_features\n",
    "}\n",
    "outs = predict_structure(jobname, feature_dict,\n",
    "                         Ls=[len(query_sequence)]*homooligomer,\n",
    "                         model_runner_and_params=model_runner_and_params,\n",
    "                         do_relax=use_amber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "6xbvRNrwnJqj"
   },
   "outputs": [],
   "source": [
    "#@title Make plots\n",
    "\n",
    "plot_lddt(homooligomer, jobname, msa, outs, query_sequence, Path(\".\"), show=True)\n",
    "plot_predicted_alignment_error(jobname, num_models, outs, Path(\".\"), show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "KK7X9T44pWb7"
   },
   "outputs": [],
   "source": [
    "#@title Display 3D structure {run: \"auto\"}\n",
    "model_num = 1 #@param [\"1\", \"2\", \"3\", \"4\", \"5\"] {type:\"raw\"}\n",
    "color = \"lDDT\" #@param [\"chain\", \"lDDT\", \"rainbow\"]\n",
    "show_sidechains = False #@param {type:\"boolean\"}\n",
    "show_mainchains = False #@param {type:\"boolean\"}\n",
    "\n",
    "show_pdb(use_amber, jobname, homooligomer, model_num, show_sidechains, show_mainchains, color).show()\n",
    "if color == \"lDDT\": plot_plddt_legend().show()\n",
    "plot_confidence(outs, homooligomer, query_sequence, model_num).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "33g5IIegij5R"
   },
   "outputs": [],
   "source": [
    "#@title Package and download results\n",
    "#@markdown If you are having issues downloading the result archive, try disabling your adblocker and run this cell again. If that fails click on the little folder icon to the left, navigate to file: `jobname.result.zip`, right-click and select \\\"Download\\\" (see [screenshot](https://pbs.twimg.com/media/E6wRW2lWUAEOuoe?format=jpg&name=small)).\n",
    "\n",
    "if use_custom_msa:\n",
    "  print(\"Don't forget to cite your custom MSA generation method.\")\n",
    "\n",
    "!zip -FSr $jobname\".result.zip\" $jobname\".log\" $a3m_file $jobname\"_\"*\"relaxed_model_\"*\".pdb\" $jobname\"_coverage_lDDT.png\" $jobname\".bibtex\" $jobname\"_PAE.png\"\n",
    "files.download(f\"{jobname}.result.zip\")\n",
    "\n",
    "if save_to_google_drive == True and drive:\n",
    "  uploaded = drive.CreateFile({'title': f\"{jobname}.result.zip\"})\n",
    "  uploaded.SetContentFile(f\"{jobname}.result.zip\")\n",
    "  uploaded.Upload()\n",
    "  print(f\"Uploaded {jobname}.result.zip to Google Drive with ID {uploaded.get('id')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UGUBLzB3C6WN"
   },
   "source": [
    "# Instructions <a name=\"Instructions\"></a>\n",
    "**Quick start**\n",
    "1. Paste your protein sequence in the input field.\n",
    "2. Press \"Runtime\" -> \"Run all\".\n",
    "3. The pipeline consists of 8 steps. The currently running steps is indicated by a circle with a stop sign next to it.\n",
    "\n",
    "**Result zip file contents**\n",
    "\n",
    "1. PDB formatted structures sorted by avg. pIDDT. (unrelaxed and relaxed if `use_amber` is enabled).\n",
    "2. Plots of the model quality.\n",
    "3. Plots of the MSA coverage.\n",
    "4. Parameter log file.\n",
    "5. A3M formatted input MSA.\n",
    "6. BibTeX file with citations for all used tools and databases.\n",
    "\n",
    "At the end of the job a download modal box will pop up with a `jobname.result.zip` file. Additionally, if the `save_to_google_drive` option was selected, the `jobname.result.zip` will be uploaded to your Google Drive.\n",
    "\n",
    "**Using a custom MSA as input**\n",
    "\n",
    "To predict the structure with a custom MSA (A3M formatted): (1) Change the msa_mode: to \"custom\", (2) Wait for an upload box to appear at the end of the \"Input Protein ...\" box. Upload your A3M. The first fasta entry of the A3M must be the query sequence without gaps.\n",
    "\n",
    "As an alternative for MSA generation the [HHblits Toolkit server](https://toolkit.tuebingen.mpg.de/tools/hhblits) can be used. After submitting your query, click \"Query Template MSA\" -> \"Download Full A3M\". Download the A3M file and upload it in this notebook.\n",
    "\n",
    "**Troubleshooting**\n",
    "* Check that the runtime type is set to GPU at \"Runtime\" -> \"Change runtime type\".\n",
    "* Try to restart the session \"Runtime\" -> \"Factory reset runtime\".\n",
    "* Check your input sequence.\n",
    "\n",
    "**Known issues**\n",
    "* Google Colab assigns different types of GPUs with varying amount of memory. Some might not have enough memory to predict the structure for a long sequence.\n",
    "* Your browser can block the pop-up for downloading the result file. You can choose the `save_to_google_drive` option to upload to Google Drive instead or manually download the result file: Click on the little folder icon to the left, navigate to file: `jobname.result.zip`, right-click and select \\\"Download\\\" (see [screenshot](https://pbs.twimg.com/media/E6wRW2lWUAEOuoe?format=jpg&name=small)).\n",
    "\n",
    "**Limitations**\n",
    "* Computing resources: Our MMseqs2 API can handle ~20-50k requests per day.\n",
    "* MSAs: MMseqs2 is very precise and sensitive but might find less hits compared to HHblits/HMMer searched against BFD or Mgnify.\n",
    "* We recommend to additionally use the full [AlphaFold2 pipeline](https://github.com/deepmind/alphafold).\n",
    "\n",
    "**Description of the plots**\n",
    "*   **Number of sequences per position** - We want to see at least 30 sequences per position, for best performance, ideally 100 sequences.\n",
    "*   **Predicted lDDT per position** - model confidence (out of 100) at each position. The higher the better.\n",
    "*   **Predicted Alignment Error** - For homooligomers, this could be a useful metric to assess how confident the model is about the interface. The lower the better.\n",
    "\n",
    "**Bugs**\n",
    "- If you encounter any bugs, please report the issue to https://github.com/sokrypton/ColabFold/issues\n",
    "\n",
    "\n",
    "**Acknowledgments**\n",
    "- We thank the AlphaFold team for developing an excellent model and open sourcing the software. \n",
    "\n",
    "- [SÃ¶ding Lab](https://www.mpibpc.mpg.de/soeding) for providing the computational resources for the MMseqs2 server\n",
    "\n",
    "- Minkyung Baek ([@minkbaek](https://twitter.com/minkbaek)) and Yoshitaka Moriwaki ([@Ag_smith](https://twitter.com/Ag_smith)) for protein-complex prediction proof-of-concept in AlphaFold2.\n",
    "\n",
    "- [David Koes](https://github.com/dkoes) for his awesome [py3Dmol](https://3dmol.csb.pitt.edu/) plugin, without whom these notebooks would be quite boring!\n",
    "\n",
    "- Do-Yoon Kim for creating the ColabFold logo.\n",
    "\n",
    "- A colab by Sergey Ovchinnikov ([@sokrypton](https://twitter.com/sokrypton)), Milot Mirdita ([@milot_mirdita](https://twitter.com/milot_mirdita)) and Martin Steinegger ([@thesteinegger](https://twitter.com/thesteinegger)).\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "AlphaFold2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}